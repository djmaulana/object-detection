{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Feb 21 09:17:01 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 546.01                 Driver Version: 546.01       CUDA Version: 12.3     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                     TCC/WDDM  | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA GeForce 930MX         WDDM  | 00000000:01:00.0 Off |                  N/A |\n",
      "| N/A    0C    P5              N/A / 200W |    143MiB /  2048MiB |     38%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A      1572    C+G   ...2txyewy\\StartMenuExperienceHost.exe    N/A      |\n",
      "|    0   N/A  N/A      3116    C+G   ... Files\\CONEXANT\\SAII\\SmartAudio.exe    N/A      |\n",
      "|    0   N/A  N/A      6196    C+G   ...nt.CBS_cw5n1h2txyewy\\SearchHost.exe    N/A      |\n",
      "|    0   N/A  N/A      7336    C+G   ...n\\121.0.2277.128\\msedgewebview2.exe    N/A      |\n",
      "|    0   N/A  N/A      8520    C+G   ...5.0_x64__cv1g1gvanyjgm\\WhatsApp.exe    N/A      |\n",
      "|    0   N/A  N/A      8672    C+G   ...CBS_cw5n1h2txyewy\\TextInputHost.exe    N/A      |\n",
      "|    0   N/A  N/A      9960    C+G   ...64__v826wp6bftszj\\TranslucentTB.exe    N/A      |\n",
      "|    0   N/A  N/A     11916    C+G   ...Programs\\Microsoft VS Code\\Code.exe    N/A      |\n",
      "|    0   N/A  N/A     14568    C+G   ...t.LockApp_cw5n1h2txyewy\\LockApp.exe    N/A      |\n",
      "|    0   N/A  N/A     15260    C+G   ....7122.0_x64__8wekyb3d8bbwe\\Todo.exe    N/A      |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\ML\\objectDetection\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "HOME = os.getcwd()\n",
    "print(HOME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.196  Python-3.11.5 torch-2.2.0+cpu CPU (Intel Core(TM) i5-6200U 2.30GHz)\n",
      "Setup complete  (4 CPUs, 11.9 GB RAM, 709.3/931.5 GB disk)\n"
     ]
    }
   ],
   "source": [
    "from IPython import display\n",
    "display.clear_output()\n",
    "\n",
    "import ultralytics\n",
    "ultralytics.checks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading Roboflow workspace...\n",
      "loading Roboflow project...\n"
     ]
    }
   ],
   "source": [
    "from roboflow import Roboflow\n",
    "rf = Roboflow(api_key=\"P7lpDjDnnF6of50XsAdz\")\n",
    "project = rf.workspace(\"apd-detection\").project(\"apd-detection-vrpms\")\n",
    "dataset = project.version(1).download(\"yolov8\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\ML\\objectDetection\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "# Train Dataset\n",
    "%cd {HOME}\n",
    "\n",
    "!yolo task=detect mode=train model=yolov8n.pt data={dataset.location}/data.yaml epochs=25 imgsz=128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\ML\\objectDetection\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.196  Python-3.11.5 torch-2.2.0+cpu CPU (Intel Core(TM) i5-6200U 2.30GHz)\n",
      "Model summary (fused): 168 layers, 3007013 parameters, 0 gradients, 8.1 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning D:\\ML\\objectDetection\\apd-detection-1\\valid\\labels.cache... 47 images, 0 backgrounds, 0 corrupt: 100%|██████████| 47/47 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning D:\\ML\\objectDetection\\apd-detection-1\\valid\\labels.cache... 47 images, 0 backgrounds, 0 corrupt: 100%|██████████| 47/47 [00:00<?, ?it/s]\n",
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  33%|███▎      | 1/3 [00:00<00:01,  1.68it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  67%|██████▋   | 2/3 [00:01<00:00,  1.35it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:02<00:00,  1.33it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:02<00:00,  1.36it/s]\n",
      "                   all         47        147       0.48      0.119      0.135     0.0675\n",
      "                 boots         47         32      0.806      0.219      0.221      0.158\n",
      "                 glove         47         16      0.132      0.125      0.134     0.0664\n",
      "               goggles         47         12      0.869     0.0833      0.273      0.085\n",
      "                  helm         47         51     0.0982     0.0196    0.00731    0.00272\n",
      "               noglove         47         27      0.252      0.222       0.16     0.0999\n",
      "             nogoggles         47          3          1          0     0.0119    0.00356\n",
      "                nohelm         47          6      0.203      0.167      0.141     0.0574\n",
      "Speed: 0.4ms preprocess, 22.2ms inference, 0.0ms loss, 1.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\val2\u001b[0m\n",
      " Learn more at https://docs.ultralytics.com/modes/val\n"
     ]
    }
   ],
   "source": [
    "# Validate Model\n",
    "%cd {HOME}\n",
    "\n",
    "!yolo task=detect mode=val model={HOME}/runs/detect/train2/weights/best.pt data={dataset.location}/data.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\ML\\objectDetection\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.196  Python-3.11.5 torch-2.2.0+cpu CPU (Intel Core(TM) i5-6200U 2.30GHz)\n",
      "Model summary (fused): 168 layers, 3007013 parameters, 0 gradients, 8.1 GFLOPs\n",
      "\n",
      "image 1/1 d:\\ML\\objectDetection\\sample.jpg: 96x128 (no detections), 46.8ms\n",
      "Speed: 1.0ms preprocess, 46.8ms inference, 2.1ms postprocess per image at shape (1, 3, 96, 128)\n",
      "Results saved to \u001b[1mruns\\detect\\predict4\u001b[0m\n",
      " Learn more at https://docs.ultralytics.com/modes/predict\n"
     ]
    }
   ],
   "source": [
    "# Predict\n",
    "%cd {HOME}\n",
    "\n",
    "!yolo task=detect mode=predict model={HOME}/runs/detect/train2/weights/best.pt conf=0.25 source={HOME}/sample.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading Roboflow workspace...\n",
      "loading Roboflow project...\n",
      "{'predictions': [{'x': 1716, 'y': 615, 'width': 36, 'height': 33, 'confidence': 0.8425694704055786, 'class': 'helm', 'class_id': 3, 'detection_id': '0dbc4b65-9fe6-4904-848d-f5283dec3656', 'image_path': 'sample.jpg', 'prediction_type': 'ObjectDetectionModel'}, {'x': 1707, 'y': 800, 'width': 30, 'height': 35, 'confidence': 0.7858035564422607, 'class': 'boots', 'class_id': 0, 'detection_id': '38752a4b-cbba-48fb-ab65-45c825bf45c5', 'image_path': 'sample.jpg', 'prediction_type': 'ObjectDetectionModel'}, {'x': 1747, 'y': 714, 'width': 21, 'height': 32, 'confidence': 0.6646450757980347, 'class': 'noglove', 'class_id': 4, 'detection_id': 'af3a0ff1-08fb-4caa-8be2-1aad2df3215e', 'image_path': 'sample.jpg', 'prediction_type': 'ObjectDetectionModel'}, {'x': 1650, 'y': 239, 'width': 18, 'height': 16, 'confidence': 0.6300569176673889, 'class': 'helm', 'class_id': 3, 'detection_id': 'fc981a2f-8040-4d54-9ec4-0244fd2691b4', 'image_path': 'sample.jpg', 'prediction_type': 'ObjectDetectionModel'}, {'x': 1603, 'y': 335, 'width': 21, 'height': 16, 'confidence': 0.5217283964157104, 'class': 'helm', 'class_id': 3, 'detection_id': '2ef34d56-1bb9-4daa-a714-fe7b07e9de64', 'image_path': 'sample.jpg', 'prediction_type': 'ObjectDetectionModel'}, {'x': 1671, 'y': 697, 'width': 18, 'height': 18, 'confidence': 0.43297910690307617, 'class': 'noglove', 'class_id': 4, 'detection_id': '87ea60f1-1d8e-49a2-8397-a34bacb2ac32', 'image_path': 'sample.jpg', 'prediction_type': 'ObjectDetectionModel'}], 'image': {'width': '1920', 'height': '1080'}}\n"
     ]
    }
   ],
   "source": [
    "# Sample using model Pre-trained using Roboflow\n",
    "rf = Roboflow(api_key=\"P7lpDjDnnF6of50XsAdz\")\n",
    "project = rf.workspace().project(\"apd-detection-vrpms\")\n",
    "model = project.version(1).model\n",
    "\n",
    "# infer on a local image\n",
    "print(model.predict(\"img/sample.jpg\", confidence=40, overlap=30).json())\n",
    "\n",
    "# visualize your prediction\n",
    "# model.predict(\"your_image.jpg\", confidence=40, overlap=30).save(\"prediction.jpg\")\n",
    "\n",
    "# infer on an image hosted elsewhere\n",
    "# print(model.predict(\"URL_OF_YOUR_IMAGE\", hosted=True, confidence=40, overlap=30).json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize your prediction\n",
    "model.predict(\"img/sample2.jpg\", confidence=40, overlap=30).save(\"prediction2.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading Roboflow workspace...\n",
      "loading Roboflow project...\n"
     ]
    }
   ],
   "source": [
    "rf = Roboflow(api_key=\"P7lpDjDnnF6of50XsAdz\")\n",
    "project = rf.workspace().project(\"apd-detection-vrpms\")\n",
    "model = project.version(1).model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
